{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Pn2qQy2RVhlX",
    "outputId": "28d210df-37b6-42b7-f6b1-c229dc5d63d6"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9dbeaa675402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(torch.cuda.is_available())\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9uvspKcVqPw"
   },
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "classes = 10\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "PniTRfttV8AJ",
    "outputId": "bb7aae83-c369-42d5-a33a-bec20a6177d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:05, 1810376.99it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 328813.12it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:00, 5301707.80it/s]                           \n",
      "8192it [00:00, 130733.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = dsets.MNIST(root='./data',train=False,transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3jLUcuNV__T"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "  def __init__(self,no_of_weights):\n",
    "    super(Autoencoder,self).__init__()\n",
    "\n",
    "    self.encoder = nn.Sequential(\n",
    "        nn.Linear(28*28, 256),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(256, no_of_weights),\n",
    "        nn.ReLU(True)\n",
    "    )\n",
    "    self.decoder = nn.Sequential(\n",
    "        nn.Linear(no_of_weights, 256),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(256, 28*28),\n",
    "        nn.ReLU(True)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.encoder(x)\n",
    "    out = self.decoder(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gxbscz_0WFXd"
   },
   "outputs": [],
   "source": [
    "def training_AE(epochs, no_of_weights, train_loader, optimisation = 'adam', lr = 0.01):\n",
    "  ae = Autoencoder(no_of_weights)\n",
    "  if use_cuda and torch.cuda.is_available():\n",
    "    ae.cuda()\n",
    "  \n",
    "  criterion = nn.MSELoss()\n",
    "  \n",
    "  if optimisation == 'adam':\n",
    "    optimizer = optim.Adam(ae.parameters(), lr)\n",
    "  elif optimisation == 'SGDmom':\n",
    "    optimizer = optim.SGD(ae.parameters(), lr, nesterov = True, dampening = 0, momentum=0.01)\n",
    "  elif optimisation == 'SGD':\n",
    "    optimizer = optim.SGD(ae.parameters(), lr)\n",
    "  elif optimisation == 'RMS':\n",
    "    optimizer = optim.RMSprop(ae.parameters(), lr)\n",
    "  \n",
    "  losses = []\n",
    "  for epoch in range(epochs):\n",
    "    running_loss,cnt = 0.0,0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "      images = Variable(images.view(images.size(0),-1))\n",
    "      labels = Variable(labels)\n",
    "      \n",
    "      if use_cuda and torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      outputs = ae(images)\n",
    "      loss = criterion(outputs, images)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "      cnt+=1\n",
    "    epoch_loss = running_loss/cnt\n",
    "    print('Epoch [%d/%d], Loss = %.5f'%(epoch+1,epochs,epoch_loss))\n",
    "    losses.append(epoch_loss)\n",
    "  \n",
    "  return losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "M44YAmkVWPdI",
    "outputId": "3a43bfc7-fbb5-4497-e2e1-a273ba5b623b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss = 0.07960\n",
      "Epoch [2/10], Loss = 0.07773\n",
      "Epoch [3/10], Loss = 0.07735\n",
      "Epoch [4/10], Loss = 0.07695\n",
      "Epoch [5/10], Loss = 0.07685\n"
     ]
    }
   ],
   "source": [
    "weights = range(4,60,4)\n",
    "optimizers = ['adam', 'SGDmom', 'SGD', 'RMS']\n",
    "losses_ae = np.zeros((4,len(weights)))\n",
    "i = 0\n",
    "for optimizer in optimizers:\n",
    "  error = []\n",
    "  for weight in weights:\n",
    "    err = training_AE(epochs, weight, train_loader, optimizer)\n",
    "    error.append(err)\n",
    "  losses_ae[i,:] = error\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oz8uD40kWUSt"
   },
   "outputs": [],
   "source": [
    "tmp = 141\n",
    "fig = plt.figure(figsize = [12,12], dpi = 60)\n",
    "for k in range(len(optimizers)):\n",
    "  plt.subplot(tmp)\n",
    "  plt.title(\"Optimizer :\" + str(optimizers[k]))\n",
    "  plt.plot(weights,losses_ae[k,:])\n",
    "  tmp+=1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PSET20HW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
